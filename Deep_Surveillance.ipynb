{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Surveillance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJhkbdga6LKdGmvkIDODmS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chachia-wacef/ComputerVision/blob/main/Deep_Surveillance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWbi3TWdYzxn"
      },
      "source": [
        "#Link for Dataset : http://www.cse.cuhk.edu.hk/leojia/projects/detectabnormal/dataset.html"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxTq_2b0bZQU"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array,load_img\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "import os \r\n",
        "import cv2\r\n",
        "\r\n",
        "from keras.layers import Conv3D,ConvLSTM2D,Conv3DTranspose\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "import imutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQfbIv4Xbo4-"
      },
      "source": [
        "store_image=[]\r\n",
        "train_path='./train'\r\n",
        "fps=5\r\n",
        "train_videos=os.listdir('train_path')\r\n",
        "train_images_path=train_path+'/frames'\r\n",
        "os.makedirs(train_images_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4xDtpSfcCur"
      },
      "source": [
        "# Cette fonction permet de convertir les images en noir_blanc(2D) et les enregistrer dans une liste\r\n",
        "def store_inarray(image_path):\r\n",
        "    image=load_img(image_path)\r\n",
        "    image=img_to_array(image)\r\n",
        "    image=cv2.resize(image, (227,227), interpolation = cv2.INTER_AREA)\r\n",
        "    #convertir en noir et blanc\r\n",
        "    gray=0.2989*image[:,:,0]+0.5870*image[:,:,1]+0.1140*image[:,:,2]\r\n",
        "    store_image.append(gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvsMafj5cCr3"
      },
      "source": [
        "for video in train_videos:\r\n",
        "    os.system( 'ffmpeg -i {}/{} -r 1/{}  {}/frames/%03d.jpg'.format(train_path,video,fps,train_path))\r\n",
        "    #lire la liste des images dans le dossier :\r\n",
        "    images=os.listdir(train_images_path)\r\n",
        "    #parcourir les images :\r\n",
        "    for image in images:\r\n",
        "      image_path=train_image_path + '/' + image\r\n",
        "      #appliquer la fonction précédente :\r\n",
        "      store_inarray(image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCJVHxvNcCpK"
      },
      "source": [
        "#convertir la liste en array :\r\n",
        "store_image=np.array(store_image)\r\n",
        "# a : nombre des images\r\n",
        "# b : longeur d'une image\r\n",
        "# c : largeur d'une image\r\n",
        "a,b,c=store_image.shape\r\n",
        "store_image.resize(b,c,a)\r\n",
        "#normaliser les images\r\n",
        "store_image=(store_image-store_image.mean())/(store_image.std())\r\n",
        "#\r\n",
        "store_image=np.clip(store_image,0,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPQs8IOXcCmn"
      },
      "source": [
        "model=Sequential()\r\n",
        "\r\n",
        "model.add(Conv3D(filters=128,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',input_shape=(227,227,10,1),activation='tanh'))\r\n",
        "model.add(Conv3D(filters=64,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\r\n",
        "model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,padding='same',dropout=0.4,recurrent_dropout=0.3,return_sequences=True))\r\n",
        "model.add(ConvLSTM2D(filters=32,kernel_size=(3,3),strides=1,padding='same',dropout=0.3,return_sequences=True))\r\n",
        "model.add(ConvLSTM2D(filters=64,kernel_size=(3,3),strides=1,return_sequences=True, padding='same',dropout=0.5))\r\n",
        "model.add(Conv3DTranspose(filters=128,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='tanh'))\r\n",
        "model.add(Conv3DTranspose(filters=1,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',activation='tanh'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fLrf0v7cCib"
      },
      "source": [
        "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuViFmPAfQa-"
      },
      "source": [
        "#Entrainer le modéle\r\n",
        "training_data=store_image\r\n",
        "frames=training_data.shape[2]\r\n",
        "frames=frames-frames%10\r\n",
        "\r\n",
        "training_data=training_data[:,:,:frames]\r\n",
        "training_data=training_data.reshape(-1,227,227,10)\r\n",
        "training_data=np.expand_dims(training_data,axis=4)\r\n",
        "\r\n",
        "target_data=training_data.copy()\r\n",
        "\r\n",
        "epochs=5\r\n",
        "batch_size=1\r\n",
        "\r\n",
        "callback_save = ModelCheckpoint(\"saved_model.h5\", monitor=\"mean_squared_error\", save_best_only=True)\r\n",
        "\r\n",
        "callback_early_stopping = EarlyStopping(monitor='val_loss', patience=3)\r\n",
        "\r\n",
        "model.fit(training_data,target_data, batch_size=batch_size, epochs=epochs, callbacks = [callback_save,callback_early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWoqOWljhPRw"
      },
      "source": [
        "import cv2\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "import numpy as np \r\n",
        "from keras.models import load_model\r\n",
        "import argparse\r\n",
        "from PIL import Image\r\n",
        "import imutils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FrL7iUghTEj"
      },
      "source": [
        "#défénir une fonction d'erreur pour dimension=5\r\n",
        "def mean_squared_loss(x1,x2):\r\n",
        "    difference=x1-x2\r\n",
        "    a,b,c,d,e=difference.shape\r\n",
        "    n_samples=a*b*c*d*e\r\n",
        "    sq_difference=difference**2\r\n",
        "    Sum=sq_difference.sum()\r\n",
        "    distance=np.sqrt(Sum)\r\n",
        "    mean_distance=distance/n_samples\r\n",
        "\r\n",
        "    return mean_distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inIIN3QlfQXG"
      },
      "source": [
        "cap = cv2.VideoCapture(\"__path_to_custom_test_video\")\r\n",
        "print(cap.isOpened())\r\n",
        "\r\n",
        "while cap.isOpened():\r\n",
        "    imagedump=[]\r\n",
        "    #lire une image du video :\r\n",
        "    ret,frame=cap.read()\r\n",
        "\r\n",
        "    for i in range(10):\r\n",
        "        ret,frame=cap.read()\r\n",
        "        #traiter l'image obtenu (frame) et l'ajouter a la liste \"imagedump\"\r\n",
        "        image = imutils.resize(frame,width=700,height=600)\r\n",
        "        frame=cv2.resize(frame, (227,227), interpolation = cv2.INTER_AREA)\r\n",
        "        gray=0.2989*frame[:,:,0]+0.5870*frame[:,:,1]+0.1140*frame[:,:,2]\r\n",
        "        gray=(gray-gray.mean())/gray.std()\r\n",
        "        gray=np.clip(gray,0,1)\r\n",
        "        imagedump.append(gray)\r\n",
        "\r\n",
        "    imagedump=np.array(imagedump)\r\n",
        "    imagedump.resize(227,227,10)\r\n",
        "    imagedump=np.expand_dims(imagedump,axis=0)\r\n",
        "    imagedump=np.expand_dims(imagedump,axis=4)\r\n",
        "    \r\n",
        "    #\"predict\" les résultats\r\n",
        "    output=model.predict(imagedump)\r\n",
        "    #Calculer l'erreur\r\n",
        "    loss=mean_squared_loss(imagedump,output)\r\n",
        "\r\n",
        "    if frame.any()==None:\r\n",
        "        print(\"none\")\r\n",
        "\r\n",
        "    if cv2.waitKey(10) & 0xFF==ord('q'):\r\n",
        "        break\r\n",
        "    if loss>0.00068:\r\n",
        "        print('Abnormal Event Detected')\r\n",
        "        cv2.putText(image,\"Abnormal Event\",(100,80),cv2.FONT_HERSHEY_SIMPLEX,2,(0,0,255),4)\r\n",
        "\r\n",
        "    cv2_imshow(image)\r\n",
        "\r\n",
        "cap.release()\r\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rcd3CGffQSu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}